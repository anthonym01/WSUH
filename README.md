# WUSH (We see You Hear)

https://anthonym01.github.io/WSUH/

## Dates

|Event|Date|
|---|---|
|Intelectual property Rights workshop|May 14|
|Video shoot session at Utech|May 20|
|Mock Pitch Event at Utech|May 27|
|FINAL submission of Pitch Deck/Prototype Demo|June 4|
|Final Pitch Event at Jamaica Pegasus Hotel|June 8|

## To do

- Get Image recignition working
- [talkback support](https://github.com/capacitor-community/text-to-speech)
- Get [speechrecognition](https://github.com/pbakondy/cordova-plugin-speechrecognition) working
- Navigation assistance via [Google maps api](https://developers.google.com/maps/gmp-get-started)
- rework camera feed with [Continuous image classifier](https://medium.com/@davifelipemsousa/continuous-image-classifier-in-cordova-d4442735ba79)

## How WUSH works

1. Input from camera streamed to server
2. Process camera feed via python image recognition libraries or open souce image A.I. such as:

  - 

3. Speak information about objects ahead of user like roads, obstuctions or anything else which may be a hazard to a blind people.

## Vest

the vest will [induce Synesthesia](https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0030) to give people who are completely blind the illusion of sight
